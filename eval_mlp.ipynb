{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of projection module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from focal_loss.focal_loss import FocalLoss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from utils import *\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Filepath to embeddings\n",
    "fname = \"/mnt/mimic/data/HAIM/mimic_extras/embeddings.csv\"\n",
    "\n",
    "# YES-TOKEN: 3276\n",
    "# NO-TOKEN: 956"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('results/bce_vd/finetuned.pth').to('cuda')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(fname)\n",
    "\n",
    "Data = DataSplit(df)\n",
    "Data.split_data('mortality')\n",
    "\n",
    "X,V,T = Data.get_type('vd_')\n",
    "\n",
    "x_test = T.values.tolist()\n",
    "labels = Data.y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProjectandClf(\n",
       "  (encoder): Sequential(\n",
       "    (0): BatchNorm1d(99, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Linear(in_features=99, out_features=1024, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    (4): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (clf): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "x_test = select_random_subset(x_test)\n",
    "labels = select_random_subset(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liv/multimodal_healthcare/mlp_utils.py:193: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_death_small48['y'] = 1\n",
      "/home/liv/multimodal_healthcare/mlp_utils.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_alive_big48['y'] = 0\n",
      "/home/liv/multimodal_healthcare/mlp_utils.py:195: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_death_big48['y'] = 0\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "\n",
    "for i, item in enumerate(x_test):\n",
    "    inputs = torch.tensor(item, dtype=torch.float32).unsqueeze(0).to('cuda')\n",
    "    output = model.forward(inputs)\n",
    "    hard_pred = torch.argmax(output, dim=1)\n",
    "    preds.append(hard_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'results/bce_vd'\n",
    "\n",
    "with open(f\"{folder}/train_losses.pkl\", \"rb\") as input_file:\n",
    "    train_losses = pickle.load(input_file)\n",
    "\n",
    "with open(f\"{folder}/train_accs.pkl\", \"rb\") as input_file:\n",
    "    train_accs = pickle.load(input_file)\n",
    "\n",
    "with open(f\"{folder}/val_losses.pkl\", \"rb\") as input_file:\n",
    "    val_losses = pickle.load(input_file)\n",
    "\n",
    "with open(f\"{folder}/val_accs.pkl\", \"rb\") as input_file:\n",
    "    val_accs = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(len(train_losses)))\n",
    "\n",
    "repetitions = len(train_losses) // len(val_losses)\n",
    "extended_val_loss = [element for element in val_losses for _ in range(repetitions)]\n",
    "\n",
    "remaining_elements = len(train_losses) % len(val_losses)\n",
    "if remaining_elements > 0:\n",
    "    extended_val_loss += val_losses[:remaining_elements]\n",
    "\n",
    "plt.plot(x, train_losses, color='r', label='train_losses')\n",
    "plt.plot(x, extended_val_loss, color='g', label='val_losses')\n",
    "\n",
    "plt.title('Loss for training and validation')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('batch')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(len(train_accs)))\n",
    "\n",
    "repetitions = len(train_accs) // len(val_accs)\n",
    "extended_val_accs = [element for element in val_accs for _ in range(repetitions)]\n",
    "\n",
    "remaining_elements = len(train_accs) % len(val_accs)\n",
    "if remaining_elements > 0:\n",
    "    extended_val_accs += val_accs[:remaining_elements]\n",
    "\n",
    "plt.plot(x, train_accs, color='r', label='train_accs')\n",
    "plt.plot(x, extended_val_accs, color='g', label='val_accs')\n",
    "\n",
    "plt.title('Accuracy for training and validation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('batch')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_arrays = [t.cpu().numpy() for t in preds]\n",
    "preds = np.array(numpy_arrays)\n",
    "\n",
    "conf_matrix = metrics.confusion_matrix(labels, preds)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-score and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch 1/50: Train loss: 0.171, Train acc.: 0.970, Val. loss: 0.245, Val. acc.: 0.965\n",
      "Epoch 2/50: Train loss: 0.154, Train acc.: 0.973, Val. loss: 0.337, Val. acc.: 0.960\n",
      "Epoch 3/50: Train loss: 0.145, Train acc.: 0.970, Val. loss: 0.330, Val. acc.: 0.951\n",
      "Epoch 4/50: Train loss: 0.135, Train acc.: 0.974, Val. loss: 0.388, Val. acc.: 0.964\n",
      "Epoch 5/50: Train loss: 0.143, Train acc.: 0.974, Val. loss: 0.421, Val. acc.: 0.955\n",
      "Epoch 6/50: Train loss: 0.151, Train acc.: 0.974, Val. loss: 0.357, Val. acc.: 0.966\n",
      "Epoch 7/50: Train loss: 0.139, Train acc.: 0.974, Val. loss: 0.512, Val. acc.: 0.955\n",
      "Epoch 8/50: Train loss: 0.138, Train acc.: 0.976, Val. loss: 0.394, Val. acc.: 0.954\n",
      "Epoch 9/50: Train loss: 0.138, Train acc.: 0.974, Val. loss: 0.488, Val. acc.: 0.949\n",
      "Epoch 10/50: Train loss: 0.114, Train acc.: 0.979, Val. loss: 0.453, Val. acc.: 0.964\n",
      "Epoch 11/50: Train loss: 0.110, Train acc.: 0.980, Val. loss: 0.458, Val. acc.: 0.962\n",
      "Epoch 12/50: Train loss: 0.113, Train acc.: 0.980, Val. loss: 0.345, Val. acc.: 0.960\n",
      "Epoch 13/50: Train loss: 0.112, Train acc.: 0.980, Val. loss: 0.500, Val. acc.: 0.955\n",
      "Epoch 14/50: Train loss: 0.110, Train acc.: 0.980, Val. loss: 0.364, Val. acc.: 0.964\n",
      "Epoch 15/50: Train loss: 0.109, Train acc.: 0.981, Val. loss: 0.361, Val. acc.: 0.958\n",
      "Epoch 16/50: Train loss: 0.103, Train acc.: 0.981, Val. loss: 0.341, Val. acc.: 0.962\n",
      "Epoch 17/50: Train loss: 0.107, Train acc.: 0.980, Val. loss: 0.367, Val. acc.: 0.956\n",
      "Epoch 18/50: Train loss: 0.103, Train acc.: 0.980, Val. loss: 0.351, Val. acc.: 0.961\n",
      "Epoch 19/50: Train loss: 0.102, Train acc.: 0.981, Val. loss: 0.357, Val. acc.: 0.964\n",
      "Epoch 20/50: Train loss: 0.101, Train acc.: 0.982, Val. loss: 0.360, Val. acc.: 0.957\n",
      "Epoch 21/50: Train loss: 0.102, Train acc.: 0.981, Val. loss: 0.344, Val. acc.: 0.964\n",
      "Epoch 22/50: Train loss: 0.103, Train acc.: 0.982, Val. loss: 0.354, Val. acc.: 0.959\n",
      "Epoch 23/50: Train loss: 0.104, Train acc.: 0.981, Val. loss: 0.362, Val. acc.: 0.959\n",
      "Epoch 24/50: Train loss: 0.102, Train acc.: 0.981, Val. loss: 0.431, Val. acc.: 0.958\n",
      "Epoch 25/50: Train loss: 0.105, Train acc.: 0.980, Val. loss: 0.338, Val. acc.: 0.960\n",
      "Epoch 26/50: Train loss: 0.099, Train acc.: 0.981, Val. loss: 0.353, Val. acc.: 0.957\n",
      "Epoch 27/50: Train loss: 0.102, Train acc.: 0.982, Val. loss: 0.320, Val. acc.: 0.965\n",
      "Epoch 28/50: Train loss: 0.100, Train acc.: 0.982, Val. loss: 0.329, Val. acc.: 0.963\n",
      "Epoch 29/50: Train loss: 0.100, Train acc.: 0.982, Val. loss: 0.349, Val. acc.: 0.959\n",
      "Epoch 30/50: Train loss: 0.103, Train acc.: 0.981, Val. loss: 0.477, Val. acc.: 0.959\n",
      "Epoch 31/50: Train loss: 0.102, Train acc.: 0.981, Val. loss: 0.362, Val. acc.: 0.961\n",
      "Epoch 32/50: Train loss: 0.104, Train acc.: 0.981, Val. loss: 0.349, Val. acc.: 0.958\n",
      "Epoch 33/50: Train loss: 0.103, Train acc.: 0.982, Val. loss: 0.357, Val. acc.: 0.960\n",
      "Epoch 34/50: Train loss: 0.101, Train acc.: 0.982, Val. loss: 0.357, Val. acc.: 0.959\n",
      "Epoch 35/50: Train loss: 0.101, Train acc.: 0.981, Val. loss: 0.366, Val. acc.: 0.958\n",
      "Epoch 36/50: Train loss: 0.102, Train acc.: 0.981, Val. loss: 0.345, Val. acc.: 0.958\n",
      "Epoch 37/50: Train loss: 0.100, Train acc.: 0.981, Val. loss: 0.339, Val. acc.: 0.963\n",
      "Epoch 38/50: Train loss: 0.103, Train acc.: 0.982, Val. loss: 0.385, Val. acc.: 0.957\n",
      "Epoch 39/50: Train loss: 0.100, Train acc.: 0.982, Val. loss: 0.357, Val. acc.: 0.960\n",
      "Epoch 40/50: Train loss: 0.104, Train acc.: 0.981, Val. loss: 0.338, Val. acc.: 0.961\n",
      "Epoch 41/50: Train loss: 0.102, Train acc.: 0.981, Val. loss: 0.336, Val. acc.: 0.960\n",
      "Epoch 42/50: Train loss: 0.101, Train acc.: 0.981, Val. loss: 0.345, Val. acc.: 0.960\n",
      "Epoch 43/50: Train loss: 0.097, Train acc.: 0.982, Val. loss: 0.373, Val. acc.: 0.957\n",
      "Epoch 44/50: Train loss: 0.102, Train acc.: 0.981, Val. loss: 0.339, Val. acc.: 0.962\n",
      "Epoch 45/50: Train loss: 0.103, Train acc.: 0.982, Val. loss: 0.329, Val. acc.: 0.961\n",
      "Epoch 46/50: Train loss: 0.102, Train acc.: 0.982, Val. loss: 0.379, Val. acc.: 0.957\n",
      "Epoch 47/50: Train loss: 0.101, Train acc.: 0.981, Val. loss: 0.393, Val. acc.: 0.958\n",
      "Epoch 48/50: Train loss: 0.102, Train acc.: 0.981, Val. loss: 0.383, Val. acc.: 0.960\n",
      "Epoch 49/50: Train loss: 0.100, Train acc.: 0.981, Val. loss: 0.357, Val. acc.: 0.961\n",
      "Epoch 50/50: Train loss: 0.102, Train acc.: 0.981, Val. loss: 0.344, Val. acc.: 0.957\n"
     ]
    }
   ],
   "source": [
    "f1 = metrics.f1_score(labels, preds)\n",
    "auc = metrics.roc_auc_score(labels, preds)\n",
    "print('f1: ', f1)\n",
    "print('auc: ', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m x_test \u001b[38;5;241m=\u001b[39m \u001b[43mselect_random_subset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m labels \u001b[38;5;241m=\u001b[39m select_random_subset(labels)\n",
      "File \u001b[0;32m~/multimodal_healthcare/mlp_utils.py:327\u001b[0m, in \u001b[0;36mselect_random_subset\u001b[0;34m(data, subset_fraction)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "precision = metrics.precision_score(labels, preds)\n",
    "recall = metrics.recall_score(labels, preds)\n",
    "accuracy = metrics.accuracy_score(labels, preds)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)\n",
    "print('accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC-curve, FPR and TPR thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(labels, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\n",
    "\n",
    "display.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 ('gemma')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "10601c873fb2576e1e1a48994b394f584387b3d54a28d8ac07023c991446672f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
