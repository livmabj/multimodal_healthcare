{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from focal_loss.focal_loss import FocalLoss\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, WeightedRandomSampler, RandomSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "from big_utils import *\n",
    "\n",
    "# Filepath to embeddings\n",
    "fname = '/mnt/mimic/data/HAIM/mimic_extras/embeddings.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6c0b97f2bf4f3ea1e4c01f178f8861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True, \n",
    "                                         bnb_4bit_use_double_quant=True,\n",
    "                                         bnb_4bit_quant_type=\"nf4\",\n",
    "                                         bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\")\n",
    "gemma = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b\", device_map=\"auto\", quantization_config=quantization_config)\n",
    "\n",
    "# Read data & extract labels and features\n",
    "df = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liv/multimodal_healthcare/big_utils.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_death_small48['y'] = 1\n",
      "/home/liv/multimodal_healthcare/big_utils.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_alive_big48['y'] = 0\n",
      "/home/liv/multimodal_healthcare/big_utils.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_death_big48['y'] = 0\n",
      "/home/liv/multimodal_healthcare/big_utils.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_alive_small48['y'] = 0\n",
      "/home/liv/multimodal_healthcare/big_utils.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_alive_small48['y'] = 1\n",
      "/home/liv/multimodal_healthcare/big_utils.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_alive_big48['y'] = 0\n",
      "/home/liv/multimodal_healthcare/big_utils.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_death['y'] = 0\n"
     ]
    }
   ],
   "source": [
    "# Load train/val sets and create data loaders\n",
    "batch_size = 8\n",
    "\n",
    "Data = DataSplit(df)\n",
    "Data.split_data('all')\n",
    "\n",
    "X, V = Data.get_data()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_set = CustomDataset(X.values.tolist(), Data.y_train.tolist())\n",
    "val_set = CustomDataset(V.values.tolist(), Data.y_val.tolist())\n",
    "\n",
    "transposed_Y = list(map(list, zip(*Data.y_train.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan, nan, nan, nan, nan, 1.0, nan, 0.0, 1.0, nan, 0, 0], [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0, 0], [nan, nan, nan, nan, nan, 1.0, nan, 0.0, 1.0, nan, 0, 0], [nan, nan, nan, nan, nan, nan, nan, 0.0, nan, nan, 0, 0], [nan, nan, nan, nan, nan, 1.0, nan, 0.0, -1.0, 0.0, 0, 0], [nan, nan, nan, nan, nan, 1.0, nan, 0.0, 0.0, 1.0, 0, 0], [nan, nan, nan, nan, 0.0, nan, 1.0, nan, 1.0, -1.0, 0, 0], [nan, nan, -1.0, nan, nan, 1.0, 1.0, 0.0, nan, nan, 0, 0], [nan, nan, nan, nan, nan, 1.0, nan, 0.0, 1.0, nan, 0, 0], [nan, nan, nan, nan, nan, 1.0, nan, 0.0, 1.0, 0.0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(Data.y_train.tolist()[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[nan, nan, nan, nan, nan, nan, nan, -1.0, nan, nan]\n",
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[nan, nan, nan, nan, nan, nan, 0.0, nan, nan, nan]\n",
      "[1.0, nan, 1.0, nan, 1.0, 1.0, nan, 1.0, 1.0, 1.0]\n",
      "[nan, nan, nan, nan, nan, nan, 1.0, 1.0, nan, nan]\n",
      "[0.0, nan, 0.0, 0.0, 0.0, 0.0, nan, 0.0, 0.0, 0.0]\n",
      "[1.0, nan, 1.0, nan, -1.0, 0.0, 1.0, nan, 1.0, 1.0]\n",
      "[nan, nan, nan, nan, 0.0, 1.0, -1.0, nan, nan, 0.0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for y in transposed_Y:\n",
    "    print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([531.0000,  28.2259, 566.4000], device='cuda:0'), tensor([447.1579,  29.7063, 189.8547], device='cuda:0'), tensor([24.2570,  9.5087,  6.3724], device='cuda:0'), tensor([26.6124,  5.7757, 19.4862], device='cuda:0'), tensor([7.0215, 5.6005, 6.4645], device='cuda:0'), tensor([54.2875,  1.5393,  9.8220], device='cuda:0'), tensor([40.7971,  1.6119, 24.8785], device='cuda:0'), tensor([ 1.6313,  6.9998, 55.2585], device='cuda:0'), tensor([3.9512, 2.3762, 6.4547], device='cuda:0'), tensor([ 6.2528,  1.6355, 11.2530], device='cuda:0'), tensor([0.5520, 5.3042], device='cuda:0'), tensor([ 0.5133, 19.2981], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "weight_per_class = []\n",
    "for y in transposed_Y[:-2]:\n",
    "    y = torch.tensor(y)\n",
    "    w0 = len(y)/(2*sum(y == 0))\n",
    "    w1 = len(y)/(2*sum(y == 1))\n",
    "    w2 = len(y)/(2*sum(y == -1))\n",
    "    weight_per_class.append(torch.tensor([w0, w1, w2], dtype = torch.float).to(\"cuda\"))\n",
    "\n",
    "for y in transposed_Y[-2:]:\n",
    "    y = torch.tensor(y)\n",
    "    w0 = len(y)/(2*sum(y == 0))\n",
    "    w1 = len(y)/(2*sum(y == 1))\n",
    "    weight_per_class.append(torch.tensor([w0, w1], dtype = torch.float).to(\"cuda\"))\n",
    "print(weight_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = RandomSampler(train_set, replacement=False)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, sampler=sampler, num_workers=5)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting model and hyperparameters\n",
    "vd_model = AutoEncoder(1024,2048)\n",
    "ts_model = AutoEncoder(451,2048)\n",
    "n_rad_model = AutoEncoder(768,2048)\n",
    "vd_optimizer_bce = optim.Adam(vd_model.parameters(), lr=0.0005, weight_decay=0.0003)\n",
    "ts_optimizer_bce = optim.Adam(ts_model.parameters(), lr=0.0005, weight_decay=0.0003)\n",
    "n_rad_optimizer_bce = optim.Adam(n_rad_model.parameters(), lr=0.003, weight_decay=0.003)\n",
    "vd_optimizer_mse = optim.Adam(vd_model.parameters(), lr=0.0005, weight_decay=0.0003)\n",
    "ts_optimizer_mse = optim.Adam(vd_model.parameters(), lr=0.0005, weight_decay=0.0003)\n",
    "n_rad_optimizer_mse = optim.Adam(vd_model.parameters(), lr=0.003, weight_decay=0.003)\n",
    "optimizers = [vd_optimizer_bce, ts_optimizer_bce, n_rad_optimizer_bce, vd_optimizer_mse, ts_optimizer_mse, n_rad_optimizer_mse]\n",
    "#optimizers = [vd_optimizer, ts_optimizer, n_rad_optimizer]\n",
    "optimizers = [n_rad_optimizer_bce, n_rad_optimizer_mse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mse = nn.MSELoss()\n",
    "loss_fns = []\n",
    "for weight in weight_per_class:\n",
    "    loss_fns.append(nn.CrossEntropyLoss(weight=weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vd_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vd_model.to('cuda')\n",
    "# for batch_index, (x, y) in enumerate(train_loader, 1):\n",
    "#         #print('stuck')\n",
    "#         inputs, labels = x, y.to('cuda')\n",
    "#         vd_inputs = inputs['vd'].to('cuda')\n",
    "#         has_nan = torch.isnan(vd_inputs).any()\n",
    "#         if has_nan:\n",
    "#                 print('orig', has_nan)\n",
    "#                 break\n",
    "#         #print(vd_inputs.shape)\n",
    "#         enc = vd_model.encoder(vd_inputs)\n",
    "#         has_nan = torch.isnan(enc).any()\n",
    "#         if has_nan:\n",
    "#                 print('enc',has_nan)\n",
    "#                 break\n",
    "#         #print(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "tensor(7.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.2924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(7.0305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(9.5531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.2198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(9.5751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(8.9036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.9636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(9.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(6.4226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.5981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(6.4825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(3.8935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.5545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(3.9489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(4.9673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.8137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(5.0486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(4.3335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.8597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(4.4195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(2.7085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.2811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(2.7366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(6.6540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(2.1128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(6.8653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(7.7338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(1.2161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(7.8554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(8.3674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.3072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(8.3982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(4.6753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.6060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(4.7359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(4.5067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(1.2163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(4.6283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(2.6987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.6329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(2.7620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(2.7424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.7077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(2.8132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(1.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.7922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(1.4179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(1.3073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(3.1046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(1.6177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f9ff7584470>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/edgelab/miniconda3/envs/gemma/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.3828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(2.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(1.8883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(1.2233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(2.0106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(2.4978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(9.0313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(3.4009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(0.9757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.9574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(1.0714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(1.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.3836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(1.2220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(2.1644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(1.3014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(2.2946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(1.6651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.4351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(1.7086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(1.4230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.3780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(1.4608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(1.4882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(1.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(1.6033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(2.6919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.3233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(2.7242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(0.8612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.3616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.8973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(1.5299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.3097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(1.5609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(3.6453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(1.3471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(3.7800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(4.5366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(4.8121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(5.0178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(2.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(6.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(2.9037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(2.6794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.5345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(2.7329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(3.4504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.6035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(3.5107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(0.9261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.5775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.9839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(1.0636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.5583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(1.1195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(1.8918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.3265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(1.9245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(0.6697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.4494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.7146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(0.5282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.5173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.5799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(2.2125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.4775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(2.2602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n",
      "tensor(1.5168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(0.2654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "True\n",
      "tensor(1.5434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "beta = 0.1\n",
    "\n",
    "fine_tuned_vd, fine_tuned_ts, fine_tuned_n_rad, train_losses, val_losses = training_loop(vd_model, ts_model, n_rad_model, optimizers, loss_mse, loss_fns, train_loader, val_loader, num_epochs, gemma, beta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 ('gemma')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10601c873fb2576e1e1a48994b394f584387b3d54a28d8ac07023c991446672f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
