{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of projection module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from focal_loss.focal_loss import FocalLoss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from mlp_utils import *\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Filepath to embeddings\n",
    "fname = \"/mnt/mimic/data/HAIM/mimic_extras/embeddings.csv\"\n",
    "\n",
    "# YES-TOKEN: 3276\n",
    "# NO-TOKEN: 956"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True, \n",
    "                                         bnb_4bit_use_double_quant=True,\n",
    "                                         bnb_4bit_quant_type=\"nf4\",\n",
    "                                         bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\")\n",
    "gemma = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b\", device_map=\"auto\", quantization_config=quantization_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('results/results_small_bce_vd/finetuned.pth').to('cuda')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Based on the following image, output yes if the patient is likely to die and no otherwise.\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "word_embs = gemma.get_input_embeddings().weight[input_ids.input_ids].to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(fname)\n",
    "\n",
    "condition_death_small48 = (df['img_length_of_stay'] < 48) & (df['death_status'] == 1)\n",
    "condition_alive_big48 = (df['img_length_of_stay'] >= 48) & (df['death_status'] == 0)\n",
    "condition_death_big48 = (df['img_length_of_stay'] >= 48) & (df['death_status'] == 1)\n",
    "\n",
    "y = [0]*len(df)\n",
    "for i, condition in enumerate(condition_death_small48):\n",
    "    if condition:\n",
    "        y[i] = 1\n",
    "\n",
    "vd_cols = df.filter(regex='^vd_')\n",
    "y_col = pd.Series(y, name='y')\n",
    "haim_col = df[['haim_id']]\n",
    "df = pd.concat([haim_col, vd_cols, y_col], axis=1)\n",
    "\n",
    "pkl_list = df['haim_id'].unique().tolist()\n",
    "\n",
    "_, _, x_test, _, _ , labels = data_split(df, pkl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(fname)\n",
    "\n",
    "Data = DataSplit(df)\n",
    "Data.split_data('mortality')\n",
    "\n",
    "X,V,T = Data.get_type('vd_')\n",
    "\n",
    "x_test = T.values.tolist()\n",
    "labels = Data.y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "x_test = select_random_subset(x_test)\n",
    "labels = select_random_subset(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for i, item in enumerate(x_test):\n",
    "    inputs = torch.tensor(item, dtype=torch.float32).unsqueeze(0).to('cuda')\n",
    "    emb = model.forward(inputs).to(torch.float16)\n",
    "    #concatted = torch.cat((word_embs, emb), dim=1).to(torch.float16)\n",
    "    #emb = emb.squeeze(0)\n",
    "    outputs = custom_output(emb, gemma)\n",
    "    preds.append(output_to_label(outputs))\n",
    "    if i % 100 == 0:\n",
    "        print('item num ', i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'results/results_small_bce_vd'\n",
    "\n",
    "with open(f\"{folder}/train_losses.pkl\", \"rb\") as input_file:\n",
    "    train_losses = pickle.load(input_file)\n",
    "\n",
    "with open(f\"{folder}/train_accs.pkl\", \"rb\") as input_file:\n",
    "    train_accs = pickle.load(input_file)\n",
    "\n",
    "with open(f\"{folder}/val_losses.pkl\", \"rb\") as input_file:\n",
    "    val_losses = pickle.load(input_file)\n",
    "\n",
    "with open(f\"{folder}/val_accs.pkl\", \"rb\") as input_file:\n",
    "    val_accs = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(len(train_losses)))\n",
    "\n",
    "repetitions = len(train_losses) // len(val_losses)\n",
    "extended_val_loss = [element for element in val_losses for _ in range(repetitions)]\n",
    "\n",
    "remaining_elements = len(train_losses) % len(val_losses)\n",
    "if remaining_elements > 0:\n",
    "    extended_val_loss += val_losses[:remaining_elements]\n",
    "\n",
    "plt.plot(x, train_losses, color='r', label='train_losses')\n",
    "plt.plot(x, extended_val_loss, color='g', label='val_losses')\n",
    "\n",
    "plt.title('Loss for training and validation')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('batch')\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(len(train_accs)))\n",
    "\n",
    "repetitions = len(train_accs) // len(val_accs)\n",
    "extended_val_accs = [element for element in val_accs for _ in range(repetitions)]\n",
    "\n",
    "remaining_elements = len(train_accs) % len(val_accs)\n",
    "if remaining_elements > 0:\n",
    "    extended_val_accs += val_accs[:remaining_elements]\n",
    "\n",
    "plt.plot(x, train_accs, color='r', label='train_losses')\n",
    "plt.plot(x, extended_val_accs, color='g', label='val_losses')\n",
    "\n",
    "plt.title('Accuracy for training and validation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('batch')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_arrays = [t.cpu().numpy() for t in preds]\n",
    "preds = np.array(numpy_arrays)\n",
    "\n",
    "conf_matrix = metrics.confusion_matrix(labels, preds)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-score and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = metrics.f1_score(labels, preds)\n",
    "auc = metrics.roc_auc_score(labels, preds)\n",
    "print('f1: ', f1)\n",
    "print('auc: ', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = metrics.precision_score(labels, preds)\n",
    "recall = metrics.recall_score(labels, preds)\n",
    "accuracy = metrics.accuracy_score(labels, preds)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)\n",
    "print('accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC-curve, FPR and TPR thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(labels, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\n",
    "\n",
    "display.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
